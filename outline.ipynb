{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELIVERABLES \n",
    "- Perform EDA with visualizations to assist in feature selection and engineering\n",
    "- Convert the CSV to a Postgres database and create a python function to easily add new\n",
    "students to the Postgres database. Ensure the database schema has appropriate\n",
    "datatypes.\n",
    "- Selection and/or engineer the feature set you will use for your model\n",
    "- Select and train a model to predict the final grade of a student.\n",
    "- Tune the model to get the best results possible\n",
    "- Generate valid metrics to evaluate your model\n",
    "\n",
    "## BONUS \n",
    "- Create another model that predicts final grades without using any of the previous\n",
    "period grades. This would be immensely helpful to the company to aid in predicting\n",
    "student performance before they fall behind\n",
    "- Write a full Data Analysis report on the statistics gleaned from the dataset\n",
    "- Include documentation used to plan out this project and its timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REQUIREMENTS\n",
    "- All code shall be written in python or SQL\n",
    "- All code shall be managed via git\n",
    "- The repository shall be named ‘<first_name>-<last_name>-aml-student-regression' (all\n",
    "lowercase, i.e. Tom Cruise’s repository name is ‘tom-cruise-aml-capstone')\n",
    "- Only libraries inherent to python or listed below can be used\n",
    "- The Postgres database should be managed via docker\n",
    "- Only data from the given dataset will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLINE \n",
    "1. CSV to Postgres\n",
    "    - DONE CSV to Postgres DB\n",
    "    - Function to add new students to DB \n",
    "2. EDA \n",
    "    - DONE Preprocessing: \n",
    "        - Handle NAs (imputing or removing)\n",
    "        - Remove duplicates \n",
    "    - Visuals:\n",
    "        - Distributions (histogram or boxplot)\n",
    "        - Correlation/MI (heat map)\n",
    "3. Feature engineering\n",
    "    - DONE Ratios for high collinear (n/a too many categorical categories)\n",
    "    - DONE Log to normalize distribution (n/a all categories are discrete)\n",
    "    - Scaling (do after test/train split to prevent data leakage)\n",
    "    - Feature selection (probably k best?) with different number of features\n",
    "4. Model implementation and evaluation\n",
    "    - DONE Make test/train set\n",
    "    - Implement pipelines\n",
    "    - Normalize\n",
    "    - Test different models\n",
    "        - Hyperparameter tuning\n",
    "        - Feature combos\n",
    "    - Evaluate\n",
    "        - Acc, pre, re, f1\n",
    "        - Cross validation? \n",
    "5. Repeat for model without grade data! \n",
    "6. Data Analytics report\n",
    "    - EDA \n",
    "    - Data preprocessing\n",
    "    - Model selection\n",
    "    - Model tuning \n",
    "    - Model without grades\n",
    "    - Analysis/conclusion\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAILY TASK LOG / NOTES\n",
    "## Friday 1/12\n",
    "* Loaded data into python and started EDA \n",
    "* Lots of categorical features -- need to figure out best way to handle\n",
    "\n",
    "## Monday 1/15\n",
    "* Got SQL db up and running\n",
    "    * To start docker: \n",
    "        1. Open Docker app\n",
    "        2. Be in directory of docker-compose.yaml\n",
    "        3. Command line: docker-compose up\n",
    "    * To get into pgadmin: \n",
    "        1. Open PGAdmin\n",
    "        2. Add new server\n",
    "        3. Put in user and password, server name = localhost \n",
    "    * Started function to add new students but didn't finish\n",
    "* Did more EDA \n",
    "* Feature engineering\n",
    "    * Made total alcohol consumption + parental education metrics\n",
    "    * Encoding nominal data and binary data\n",
    "* Testing models \n",
    "    * Feature selection algorithm\n",
    "    * Looking at logistic, SVC, KNeighbors ? \n",
    "### Issues\n",
    "* Need to figure out if I encode before or after selecting K best features -- if before, then how do I encode in a way that preserves the feature info\n",
    "    * Also, is it ok to just select parts of the encoded feature for the regression or do I need the whole thing lols\n",
    "* Implementing pipeline? \n",
    "* Need to clarify if this is classification\n",
    "* Do we need to normalize values? \n",
    "## Tuesday 1/16\n",
    "* Made visuals for EDA\n",
    "* Finished postgres function \n",
    "    * Could clean up so you don't need to feed it 33 parameters lol ; feed it dictionary instead?\n",
    "* Hyperparameter tuning\n",
    "    * Alpha for ridge: decreases curve complexity (less overfitting)\n",
    "* Got 5 best models\n",
    "### Issues\n",
    "* Should I customize feature selection for each model type? I think yes but not sure...\n",
    "* How to deal with percent error calculation\n",
    "    * Currently handling as MAE / mean\n",
    "    * How to deal with 0 true value\n",
    "* Understand how docker works\n",
    "* When tuning hyperparameters, I get worse performance than just the default settings? \n",
    "## Wednesday 1/17\n",
    "* Goals:\n",
    "    * Have all models done\n",
    "    * Make visuals \n",
    "    * Start report\n",
    "* Started no grades model -- very bad performance so far\n",
    "* SGD breaks with hyperparameter tuning for some reason\n",
    "## Thursday 1/18\n",
    "* Goals:\n",
    "    * First draft of report done \n",
    "    * Visuals done\n",
    "\n",
    "## Friday 1/19\n",
    "* Goals:\n",
    "    * Clean up visuals \n",
    "    * Clean up report\n",
    "    * Final test run\n",
    "    * All done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
