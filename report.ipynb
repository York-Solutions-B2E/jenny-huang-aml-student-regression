{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:\n",
    "Given various data about a student's personal and academic circumstances, can we predict their final trimester grades?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset explanation / Exploratory Data Analysis (EDA):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering and selection:\n",
    "-Engineered features\n",
    "-Encoding  \n",
    "-K Best features selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection and testing:\n",
    "A total of 6 regression models were tested: \n",
    "- Random Forest\n",
    "- Gradient Boosting Tree\n",
    "- K Neighbors \n",
    "- SVR\n",
    "- Ridge Regression\n",
    "- Stochastic Gradient Descent\n",
    "Talk about rationale for choosing these \n",
    "\n",
    "For each model type, the ideal number of features was chosen by iterating through the feature set choosing the k best features based on mutual information for k = 3 up to the max number of features (49 after one hot encoding categorical features). \n",
    "<!-- insert kfeatures.png-->\n",
    "The performance for each model was evaluated based on the following metrics:\n",
    "- R^2 \n",
    "- Mean squared error (MSE)\n",
    "- Mean absolute error (MAE)\n",
    "- Relative error: MAE/mean target value (as a proxy for percent error, which was unable to be calculated due to 0 being a true value)\n",
    "\n",
    "For each model, the best performing feature combination was returned based on relative error: \n",
    "<!-- ![Sample Image](figures/relative_e_feature_selection.png)figure out how to resize -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "-Best model\n",
    "    -Best model was KNeighbors, then RandomForest and GradientBoostingTree\n",
    "-Best feature set\n",
    "-Most important features \n",
    "    - G1 , G2, Gavg\n",
    "\n",
    "- Across different runs, the number of ideal features fluctuated but the best performing models were consistent, and G1, G2, Gavg were always selected\n",
    "    - Implies that many of these features have minimal predictive power compared to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression without grade data \n",
    "-Improved performance after scaling age and absence (show data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall limitations and next steps\n",
    "- Scoring for choosing k best features was based on mutual information \n",
    "- Normalizing data \n",
    "- Feature selection of encoded features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
